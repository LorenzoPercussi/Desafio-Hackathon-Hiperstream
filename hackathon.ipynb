{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00942808-d35f-4b87-8488-1234b3a1e45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1ac23d1-238f-4428-bd60-5d0d99f585a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ID': '1', 'Nome': 'Aplicacao1', 'PastaOrigem': 'C:\\\\EntradaA\\\\', 'PastaDestino': 'C:\\\\Entrada2\\\\', 'PastaBackup': 'C:\\\\Guarda\\\\'}, {'ID': '2', 'Nome': 'Aplicacao2', 'PastaOrigem': 'C:\\\\Entrada2\\\\', 'PastaDestino': 'C:\\\\Aplicacao2Dest\\\\', 'PastaBackup': 'C:\\\\Voa'}, {'ID': '3', 'Nome': 'Aplicacao3', 'PastaOrigem': 'C:\\\\Voa', 'PastaDestino': '', 'PastaBackup': 'C:\\\\Guarda\\\\'}, {'ID': '4', 'Nome': 'Aplicacao4', 'PastaOrigem': 'C:\\\\Entrada2\\\\', 'PastaDestino': '', 'PastaBackup': 'C:\\\\Guarda\\\\'}, {'ID': '5', 'Nome': 'Aplicacao5', 'PastaOrigem': 'C:\\\\monitorada\\\\3k\\\\', 'PastaDestino': 'C:\\\\monitorada\\\\ds\\\\', 'PastaBackup': 'C:\\\\monitorada\\\\Gd\\\\'}, {'ID': '6', 'Nome': 'Aplicacao6', 'PastaOrigem': 'C:\\\\Aplicacao2Dest\\\\', 'PastaDestino': '', 'PastaBackup': ''}]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('Exemplo.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header\n",
    "    for row in reader:\n",
    "        labels = row[0].split(';')  # Split by delimiter\n",
    "        row_dict = {'ID': labels[0],\n",
    "                    'Nome': labels[1],\n",
    "                    'PastaOrigem': labels[2],\n",
    "                    'PastaDestino': labels[3],\n",
    "                    'PastaBackup': labels[4]}  # Create dictionary\n",
    "        data.append(row_dict)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5e8251d-4f53-4cd8-9ccc-8d660afe171c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def verifica_dados(dataset):\n",
    "    padrao_pasta = r'^(?:[a-zA-Z]:[\\\\\\/]|\\\\\\\\)(?:[a-zA-Z0-9]+[\\\\\\/])*[a-zA-Z0-9]'\n",
    "    padrao_id = set()\n",
    "    dados_limpos = []\n",
    "    \n",
    "    for row in dataset:\n",
    "        # Limpa as entradas\n",
    "        id_ = row['ID'].strip()  # Renomeado para 'id_' para evitar conflito com a função id() do Python\n",
    "        pasta_origem = row['PastaOrigem'].strip()\n",
    "        pasta_destino = row['PastaDestino'].strip()\n",
    "        pasta_backup = row['PastaBackup'].strip()\n",
    "        \n",
    "        # Verifica IDs repetidos\n",
    "        if id_ in padrao_id:\n",
    "            print(f\"ID repetido encontrado: {id_}\")\n",
    "        else:\n",
    "            padrao_id.add(id_)\n",
    "            # Adiciona os dados limpos à lista de dados\n",
    "            dados_limpos.append(row)\n",
    "        \n",
    "        # Verifica se origem = destino/backup\n",
    "        if pasta_origem == pasta_destino:\n",
    "            print(f\"A pasta de origem é igual à pasta de destino. ID: {id_}\")\n",
    "        \n",
    "        if pasta_origem == pasta_backup:\n",
    "            print(f\"A pasta de origem é igual à pasta de backup. ID: {id_}\")   \n",
    "        \n",
    "        # Verifica se as pastas seguem o padrão\n",
    "        if not re.match(padrao_pasta, pasta_origem) and pasta_origem != \"\":\n",
    "            print(pasta_origem)\n",
    "            print(f\"A pasta de origem não segue o padrão. ID: {id_}\")\n",
    "        \n",
    "        if not re.match(padrao_pasta, pasta_destino) and pasta_destino != \"\":\n",
    "            print(pasta_destino)\n",
    "            print(f\"A pasta de destino não segue o padrão. ID: {id_}\")\n",
    "        \n",
    "        if not re.match(padrao_pasta, pasta_backup) and pasta_backup != \"\":\n",
    "            print(pasta_backup)\n",
    "            print(f\"A pasta de backup não segue o padrão. ID: {id_}\")\n",
    "    \n",
    "    return dados_limpos\n",
    "\n",
    "dados_verificados = verifica_dados(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53cbb3b6-f1cb-444d-aa5c-514a2776d56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados limpos foram escritos com sucesso no arquivo 'dados_limpos.csv'.\n"
     ]
    }
   ],
   "source": [
    "with open('dados_limpos.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=dados_verificados[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dados_verificados)\n",
    "\n",
    "print(\"Os dados limpos foram escritos com sucesso no arquivo 'dados_limpos.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f443ac2-2555-47b2-a432-ade5bd151298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PRODUCAO\\Cliente\\FATURA\\ARMAZEM\\relatorios-regras\n",
      "A pasta de origem não segue o padrão. ID: 1\n",
      "D:\\Backup\n",
      "A pasta de destino não segue o padrão. ID: 1\n",
      "C:\\Backup\n",
      "A pasta de backup não segue o padrão. ID: 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a6417-05a9-4719-9afe-0e2d67a81607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
